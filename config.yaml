# config.yaml
model:
  d_model: 32                    # Small for testing
  n_heads: 2
  n_layers: 2
  memory_layers: 2               # Depth of neural memory (L_M)
  persistent_memory_size: 8      # Size of persistent memory (N_p)
  vocab_size: 50
  max_seq_len: 128

  # Architecture variant to use
  variant: "MAC"                 # Options: MAC, MAG, MAL, LMM

  # Memory-specific configs
  memory:
    window_size: 32              # For sliding window attention
    segment_size: 64             # For MAC chunking

training:
  batch_size: 4                  # Small for testing
  learning_rate: 1e-3
  weight_decay: 0.1
  max_epochs: 100
  gradient_clip: 1.0

  # Optimizer
  optimizer: "adamw"
  scheduler: "cosine"
  warmup_steps: 100

data:
  dataset: "copy_task"           # Which toy dataset to use
  seq_len: 64
  vocab_size: 10
  num_samples: 1000
  train_ratio: 0.8

# For reproducibility
seed: 42

# Logging
logging:
  log_level: "INFO"
  log_every: 10
  save_every: 50

# Paths
paths:
  data_dir: "./data"
  model_dir: "./models"
  log_dir: "./logs"